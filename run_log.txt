(.venv) root@MSI:/mnt/c/Daniel 2.0/Junior Year of 25-26/Fall 2025/CSCE 421/hw5# python main.py --task train --run_name hw5_test
The file './tokenizer/simple_vocab.json' exists. Loading tokenizer.
{'<pad>': 0, '<s>': 1, '</s>': 2, '<unk>': 3, 'I_TURN_RIGHT': 4, 'I_JUMP': 5, 'I_WALK': 6, 'I_TURN_LEFT': 7, 'I_RUN': 8, 'I_LOOK': 9, 'jump': 10, 'opposite': 11, 'right': 12, 'twice': 13, 'and': 14, 'turn': 15, 'thrice': 16, 'run': 17, 'left': 18, 'after': 19, 'walk': 20, 'around': 21, 'look': 22}
train dataset size: 15055
val dataset size: 1673
loading model
total params: 9408
/mnt/c/Daniel 2.0/Junior Year of 25-26/Fall 2025/CSCE 421/hw5/trainer.py:79: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler()
epoch 1 iter 0: train loss 0.00000. lr 0.0000e+00:   0%|                                                                    | 0/471 [00:00<?, ?it/s]/mnt/c/Daniel 2.0/Junior Year of 25-26/Fall 2025/CSCE 421/hw5/trainer.py:102: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
epoch 1 iter 470: train loss 1.35277. lr 3.9978e-04: 100%|████████████████████████████████████████████████████████| 471/471 [00:10<00:00, 44.91it/s]
test loss: %f 1.3425116673955377
epoch_valid_loss: 1.3425116673955377, epoch_train_loss: 2.0132758096018666, epoch: 1
Saving at epoch 1: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 1.3601036071777344 train_step: 500, learning_rate: 0.0003997489407867487                          | 26/471 [00:00<00:07, 63.28it/s]
epoch 2 iter 470: train loss 0.82298. lr 3.9902e-04: 100%|████████████████████████████████████████████████████████| 471/471 [00:07<00:00, 67.26it/s]
test loss: %f 0.8697048673089945
epoch_valid_loss: 0.8697048673089945, epoch_train_loss: 1.1038663222784701, epoch: 2
Saving at epoch 2: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.8362759947776794 train_step: 1000, learning_rate: 0.0003988910329278014                         | 57/471 [00:00<00:06, 64.85it/s]
epoch 3 iter 470: train loss 0.77805. lr 3.9773e-04: 100%|████████████████████████████████████████████████████████| 471/471 [00:07<00:00, 65.47it/s]
test loss: %f 0.6955685952924332
epoch_valid_loss: 0.6955685952924332, epoch_train_loss: 0.8405562338049498, epoch: 3
Saving at epoch 3: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.7198643088340759 train_step: 1500, learning_rate: 0.00039742625820294794                        | 86/471 [00:01<00:05, 69.79it/s]
epoch 4 iter 470: train loss 0.79001. lr 3.9590e-04: 100%|████████████████████████████████████████████████████████| 471/471 [00:07<00:00, 59.42it/s]
test loss: %f 0.6513947765782194
epoch_valid_loss: 0.6513947765782194, epoch_train_loss: 0.749257242224019, epoch: 4
Saving at epoch 4: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.6779859066009521 train_step: 2000, learning_rate: 0.00039535908601049877                       | 114/471 [00:02<00:07, 48.10it/s]
epoch 5 iter 470: train loss 0.73619. lr 3.9354e-04: 100%|████████████████████████████████████████████████████████| 471/471 [00:08<00:00, 58.52it/s]
test loss: %f 0.597723404753883
epoch_valid_loss: 0.597723404753883, epoch_train_loss: 0.7126684109116815, epoch: 5
Saving at epoch 5: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.6382982134819031 train_step: 2500, learning_rate: 0.0003926958238158596                        | 142/471 [00:02<00:05, 58.81it/s]
epoch 6 iter 470: train loss 0.76149. lr 3.9065e-04: 100%|████████████████████████████████████████████████████████| 471/471 [00:08<00:00, 56.23it/s]
test loss: %f 0.5866818950985963
epoch_valid_loss: 0.5866818950985963, epoch_train_loss: 0.6868038571058058, epoch: 6
Saving at epoch 6: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.7334414124488831 train_step: 3000, learning_rate: 0.00038944459790585885                       | 172/471 [00:03<00:05, 54.68it/s]
epoch 7 iter 470: train loss 0.45734. lr 3.8725e-04: 100%|████████████████████████████████████████████████████████| 471/471 [00:08<00:00, 57.77it/s]
test loss: %f 0.5610535729606196
epoch_valid_loss: 0.5610535729606196, epoch_train_loss: 0.6692715902237376, epoch: 7
Saving at epoch 7: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.6701356768608093 train_step: 3500, learning_rate: 0.00038561532859338987                       | 202/471 [00:03<00:05, 52.37it/s]
epoch 8 iter 470: train loss 0.84074. lr 3.8334e-04: 100%|████████████████████████████████████████████████████████| 471/471 [00:08<00:00, 58.24it/s]
test loss: %f 0.5511093409556262
epoch_valid_loss: 0.5511093409556262, epoch_train_loss: 0.6568751065594376, epoch: 8
Saving at epoch 8: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.7340565323829651 train_step: 4000, learning_rate: 0.00038121969994802686                       | 228/471 [00:03<00:03, 61.86it/s]
epoch 9 iter 470: train loss 0.61879. lr 3.7894e-04: 100%|████████████████████████████████████████████████████████| 471/471 [00:07<00:00, 62.93it/s]
test loss: %f 0.5385662671530022
epoch_valid_loss: 0.5385662671530022, epoch_train_loss: 0.6463623841603597, epoch: 9
Saving at epoch 9: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.6386558413505554 train_step: 4500, learning_rate: 0.00037627112671667753                       | 255/471 [00:04<00:03, 60.57it/s]
epoch 10 iter 470: train loss 0.70535. lr 3.7405e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 62.79it/s]
test loss: %f 0.5316711360553525
epoch_valid_loss: 0.5316711360553525, epoch_train_loss: 0.6397518099240184, epoch: 10
Saving at epoch 10: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.6280592083930969 train_step: 5000, learning_rate: 0.0003707847005411132██▊                     | 290/471 [00:04<00:03, 59.55it/s]
epoch 11 iter 470: train loss 0.77685. lr 3.6869e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 61.12it/s]
test loss: %f 0.5180342158056656
epoch_valid_loss: 0.5180342158056656, epoch_train_loss: 0.6279735660097402, epoch: 11
Saving at epoch 11: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.6105853915214539 train_step: 5500, learning_rate: 0.0003647771665180489█████▊                  | 315/471 [00:06<00:02, 55.38it/s]
epoch 12 iter 470: train loss 0.66455. lr 3.6287e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:09<00:00, 52.15it/s]
test loss: %f 0.5111398983676478
epoch_valid_loss: 0.5111398983676478, epoch_train_loss: 0.6220352977450992, epoch: 12
Saving at epoch 12: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.7615583539009094 train_step: 6000, learning_rate: 0.0003582668618277934█████████▋              | 348/471 [00:07<00:03, 35.72it/s]
epoch 13 iter 470: train loss 0.53903. lr 3.5661e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:10<00:00, 45.85it/s]
test loss: %f 0.5101359137948954
epoch_valid_loss: 0.5101359137948954, epoch_train_loss: 0.6178979719267276, epoch: 13
Saving at epoch 13: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.643809974193573 train_step: 6500, learning_rate: 0.00035127364537228863█████████████           | 377/471 [00:09<00:02, 43.67it/s]
epoch 14 iter 470: train loss 0.65731. lr 3.4993e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:12<00:00, 39.24it/s]
test loss: %f 0.49931545527476184
epoch_valid_loss: 0.49931545527476184, epoch_train_loss: 0.6095458231787266, epoch: 14
Saving at epoch 14: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.625059962272644 train_step: 7000, learning_rate: 0.00034381884763814557████████████████▎       | 405/471 [00:09<00:01, 45.65it/s]
epoch 15 iter 470: train loss 0.51418. lr 3.4284e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:10<00:00, 44.70it/s]
test loss: %f 0.48745487827175066
epoch_valid_loss: 0.48745487827175066, epoch_train_loss: 0.6029506459863829, epoch: 15
Saving at epoch 15: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.6979503631591797 train_step: 7500, learning_rate: 0.00033592522177779913██████████████████▏    | 430/471 [00:08<00:00, 64.14it/s]
epoch 16 iter 470: train loss 0.73822. lr 3.3536e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:08<00:00, 53.71it/s]
test loss: %f 0.4899739460000452
epoch_valid_loss: 0.4899739460000452, epoch_train_loss: 0.6004691149904976, epoch: 16
step_train_loss: 0.561456024646759 train_step: 8000, learning_rate: 0.0003276168616470794████████████████████████▏| 464/471 [00:07<00:00, 71.19it/s]
epoch 17 iter 470: train loss 0.75062. lr 3.2752e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 59.85it/s]
test loss: %f 0.4790109823334892
epoch_valid_loss: 0.4790109823334892, epoch_train_loss: 0.5950187989480936, epoch: 17
Saving at epoch 17: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
epoch 18 iter 470: train loss 0.57311. lr 3.1934e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 64.19it/s]
test loss: %f 0.483014130929731
epoch_valid_loss: 0.483014130929731, epoch_train_loss: 0.5899067960220791, epoch: 18
step_train_loss: 0.5480386018753052 train_step: 8500, learning_rate: 0.00031892856370618823                        | 21/471 [00:00<00:07, 56.70it/s]
epoch 19 iter 470: train loss 0.64551. lr 3.1083e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 65.17it/s]
test loss: %f 0.4651685598886238
epoch_valid_loss: 0.4651685598886238, epoch_train_loss: 0.5838674556171312, epoch: 19
Saving at epoch 19: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.5803419947624207 train_step: 9000, learning_rate: 0.00030986831410617134                        | 51/471 [00:00<00:06, 65.91it/s]
epoch 20 iter 470: train loss 0.50316. lr 3.0202e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 66.03it/s]
test loss: %f 0.46309142461362873
epoch_valid_loss: 0.46309142461362873, epoch_train_loss: 0.580143576847773, epoch: 20
Saving at epoch 20: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.5948904156684875 train_step: 9500, learning_rate: 0.0003004728463160256                         | 80/471 [00:01<00:07, 54.34it/s]
epoch 21 iter 470: train loss 0.40288. lr 2.9293e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 61.68it/s]
test loss: %f 0.45843730951255224
epoch_valid_loss: 0.45843730951255224, epoch_train_loss: 0.5747777666509025, epoch: 21
Saving at epoch 21: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.5961658954620361 train_step: 10000, learning_rate: 0.00029077081075159177                      | 107/471 [00:01<00:05, 67.77it/s]
epoch 22 iter 470: train loss 0.51101. lr 2.8359e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 63.89it/s]
test loss: %f 0.4649570994781998
epoch_valid_loss: 0.4649570994781998, epoch_train_loss: 0.5715286779175898, epoch: 22
step_train_loss: 0.4801343083381653 train_step: 10500, learning_rate: 0.00028079179083144917                      | 134/471 [00:02<00:04, 68.13it/s]
epoch 23 iter 470: train loss 0.66934. lr 2.7403e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 66.57it/s]
test loss: %f 0.45082601005176326
epoch_valid_loss: 0.45082601005176326, epoch_train_loss: 0.5691902392609104, epoch: 23
Saving at epoch 23: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.5582085847854614 train_step: 11000, learning_rate: 0.00027056627435953035                      | 162/471 [00:02<00:04, 69.90it/s]
epoch 24 iter 470: train loss 0.50047. lr 2.6427e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 66.12it/s]
test loss: %f 0.4418922049819298
epoch_valid_loss: 0.4418922049819298, epoch_train_loss: 0.5638819280576807, epoch: 24
Saving at epoch 24: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.5431656837463379 train_step: 11500, learning_rate: 0.00026012544254159104                      | 195/471 [00:03<00:04, 65.45it/s]
epoch 25 iter 470: train loss 0.53733. lr 2.5433e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 65.01it/s]
test loss: %f 0.43129961333184874
epoch_valid_loss: 0.43129961333184874, epoch_train_loss: 0.558770251691721, epoch: 25
Saving at epoch 25: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.5510055422782898 train_step: 12000, learning_rate: 0.00024950115296592005                      | 223/471 [00:03<00:03, 65.57it/s]
epoch 26 iter 470: train loss 0.56088. lr 2.4424e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 66.32it/s]
test loss: %f 0.4247774093780877
epoch_valid_loss: 0.4247774093780877, epoch_train_loss: 0.5547551579156499, epoch: 26
Saving at epoch 26: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.5031529664993286 train_step: 12500, learning_rate: 0.00023872582299629312                      | 253/471 [00:04<00:03, 67.31it/s]
epoch 27 iter 470: train loss 0.43100. lr 2.3404e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 64.47it/s]
test loss: %f 0.4224369739586452
epoch_valid_loss: 0.4224369739586452, epoch_train_loss: 0.5510063869305224, epoch: 27
Saving at epoch 27: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.5603047013282776 train_step: 13000, learning_rate: 0.0002278323092971486▎                      | 277/471 [00:04<00:02, 65.41it/s]
epoch 28 iter 470: train loss 0.53379. lr 2.2374e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 63.70it/s]
test loss: %f 0.41951138230989565
epoch_valid_loss: 0.41951138230989565, epoch_train_loss: 0.5456908881158079, epoch: 28
Saving at epoch 28: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.5497888922691345 train_step: 13500, learning_rate: 0.00021685389362485693██▋                   | 306/471 [00:04<00:02, 66.35it/s]
epoch 29 iter 470: train loss 0.71378. lr 2.1338e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 64.90it/s]
test loss: %f 0.42024269250203977
epoch_valid_loss: 0.42024269250203977, epoch_train_loss: 0.5442768442909176, epoch: 29
step_train_loss: 0.4315456748008728 train_step: 14000, learning_rate: 0.00020582405250931256██████▋               | 340/471 [00:05<00:01, 68.61it/s]
epoch 30 iter 470: train loss 0.49637. lr 2.0298e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 66.06it/s]
test loss: %f 0.41944113486218004
epoch_valid_loss: 0.41944113486218004, epoch_train_loss: 0.5397512803285238, epoch: 30
Saving at epoch 30: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.5578648447990417 train_step: 14500, learning_rate: 0.0001947764189876604██████████▋            | 366/471 [00:05<00:01, 66.83it/s]
epoch 31 iter 470: train loss 0.52099. lr 1.9258e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 64.23it/s]
test loss: %f 0.4082655878561848
epoch_valid_loss: 0.4082655878561848, epoch_train_loss: 0.5368244761873961, epoch: 31
Saving at epoch 31: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.5930752158164978 train_step: 15000, learning_rate: 0.00018374474568164296█████████████▍        | 398/471 [00:06<00:01, 60.57it/s]
epoch 32 iter 470: train loss 0.48726. lr 1.8219e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 64.71it/s]
test loss: %f 0.4054813559325236
epoch_valid_loss: 0.4054813559325236, epoch_train_loss: 0.5353282126904546, epoch: 32
Saving at epoch 32: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.5253843069076538 train_step: 15500, learning_rate: 0.00017276267122068255████████████████▋     | 425/471 [00:06<00:00, 56.47it/s]
epoch 33 iter 470: train loss 0.63960. lr 1.7185e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 61.57it/s]
test loss: %f 0.4143920523940392
epoch_valid_loss: 0.4143920523940392, epoch_train_loss: 0.5328550407081653, epoch: 33
step_train_loss: 0.5409974455833435 train_step: 16000, learning_rate: 0.000161863704659693█████████████████████▋  | 451/471 [00:07<00:00, 67.10it/s]
epoch 34 iter 470: train loss 0.56526. lr 1.6159e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 61.62it/s]
test loss: %f 0.3999743860847545
epoch_valid_loss: 0.3999743860847545, epoch_train_loss: 0.5294256609589684, epoch: 34
Saving at epoch 34: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
epoch 35 iter 470: train loss 0.38757. lr 1.5144e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 65.07it/s]
test loss: %f 0.3905826390914197
epoch_valid_loss: 0.3905826390914197, epoch_train_loss: 0.5271207673154819, epoch: 35
Saving at epoch 35: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.573257327079773 train_step: 16500, learning_rate: 0.0001510924808426786                         | 13/471 [00:00<00:10, 43.49it/s]
epoch 36 iter 470: train loss 0.41875. lr 1.4141e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 64.79it/s]
test loss: %f 0.39301501748696815
epoch_valid_loss: 0.39301501748696815, epoch_train_loss: 0.524883362328171, epoch: 36
step_train_loss: 0.45856931805610657 train_step: 17000, learning_rate: 0.00014045898638681664                      | 41/471 [00:00<00:06, 63.42it/s]
epoch 37 iter 470: train loss 0.42632. lr 1.3154e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 66.48it/s]
test loss: %f 0.38847395721471534
epoch_valid_loss: 0.38847395721471534, epoch_train_loss: 0.5219700579430647, epoch: 37
Saving at epoch 37: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.4896561801433563 train_step: 17500, learning_rate: 0.00013000710454508208                       | 72/471 [00:01<00:06, 64.99it/s]
epoch 38 iter 470: train loss 0.43568. lr 1.2186e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 64.10it/s]
test loss: %f 0.38717115431461696
epoch_valid_loss: 0.38717115431461696, epoch_train_loss: 0.5200488890685346, epoch: 38
Saving at epoch 38: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.5003947019577026 train_step: 18000, learning_rate: 0.00011976883009889161                       | 99/471 [00:01<00:05, 69.72it/s]
epoch 39 iter 470: train loss 0.57992. lr 1.1239e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 66.73it/s]
test loss: %f 0.3826922999238068
epoch_valid_loss: 0.3826922999238068, epoch_train_loss: 0.519678326991966, epoch: 39
Saving at epoch 39: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.4239639639854431 train_step: 18500, learning_rate: 0.00010977536101143186                      | 127/471 [00:02<00:05, 65.65it/s]
epoch 40 iter 470: train loss 0.54370. lr 1.0316e-04: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 66.42it/s]
test loss: %f 0.37883899796683834
epoch_valid_loss: 0.37883899796683834, epoch_train_loss: 0.5152833931891528, epoch: 40
Saving at epoch 40: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.5692561268806458 train_step: 19000, learning_rate: 0.00010005718985545179                      | 155/471 [00:02<00:04, 64.90it/s]
epoch 41 iter 470: train loss 0.43241. lr 9.4187e-05: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 63.35it/s]
test loss: %f 0.38082777666595746
epoch_valid_loss: 0.38082777666595746, epoch_train_loss: 0.5148549918915816, epoch: 41
step_train_loss: 0.4685337543487549 train_step: 19500, learning_rate: 9.064396920088103e-05                       | 188/471 [00:02<00:04, 68.20it/s]
epoch 42 iter 470: train loss 0.49564. lr 8.5503e-05: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 65.18it/s]
test loss: %f 0.37897514228550894
epoch_valid_loss: 0.37897514228550894, epoch_train_loss: 0.512179446511461, epoch: 42
step_train_loss: 0.5296465754508972 train_step: 20000, learning_rate: 8.156442113742624e-05                       | 217/471 [00:03<00:03, 68.92it/s]
epoch 43 iter 470: train loss 0.49258. lr 7.7128e-05: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 66.66it/s]
test loss: %f 0.374185544702242
epoch_valid_loss: 0.374185544702242, epoch_train_loss: 0.5082126526822457, epoch: 43
Saving at epoch 43: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.43498528003692627 train_step: 20500, learning_rate: 7.284624963629354e-05                      | 244/471 [00:03<00:03, 68.75it/s]
epoch 44 iter 470: train loss 0.58079. lr 6.9086e-05: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 66.08it/s]
test loss: %f 0.3701654706361159
epoch_valid_loss: 0.3701654706361159, epoch_train_loss: 0.5076698231216196, epoch: 44
Saving at epoch 44: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.4382246732711792 train_step: 21000, learning_rate: 6.451602398585763e-05                       | 272/471 [00:04<00:03, 66.26it/s]
epoch 45 iter 470: train loss 0.43889. lr 6.1399e-05: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 64.68it/s]
test loss: %f 0.36552048516723346
epoch_valid_loss: 0.36552048516723346, epoch_train_loss: 0.5065410223229929, epoch: 45
Saving at epoch 45: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.48417899012565613 train_step: 21500, learning_rate: 5.659922743246404e-05██                    | 300/471 [00:04<00:02, 67.23it/s]
epoch 46 iter 470: train loss 0.37144. lr 5.4087e-05: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 65.02it/s]
test loss: %f 0.37231913265192285
epoch_valid_loss: 0.37231913265192285, epoch_train_loss: 0.506282588162493, epoch: 46
step_train_loss: 0.42710810899734497 train_step: 22000, learning_rate: 4.911998248917342e-05█████▏                | 327/471 [00:05<00:02, 68.54it/s]
epoch 47 iter 470: train loss 0.35982. lr 4.7170e-05: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 66.88it/s]
test loss: %f 0.3661552498925407
epoch_valid_loss: 0.3661552498925407, epoch_train_loss: 0.5062153236248438, epoch: 47
step_train_loss: 0.4558332860469818 train_step: 22500, learning_rate: 4.210111020226544e-05█████████▉             | 359/471 [00:05<00:01, 67.82it/s]
epoch 48 iter 470: train loss 0.60162. lr 4.0667e-05: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 65.90it/s]
test loss: %f 0.3668058317787242
epoch_valid_loss: 0.3668058317787242, epoch_train_loss: 0.5048134794533885, epoch: 48
step_train_loss: 0.5394827723503113 train_step: 23000, learning_rate: 4e-05█████████████████████████████▍         | 389/471 [00:05<00:01, 68.46it/s]
epoch 49 iter 470: train loss 0.47492. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 66.44it/s]
test loss: %f 0.3650682827211776
epoch_valid_loss: 0.3650682827211776, epoch_train_loss: 0.5023602247870905, epoch: 49
Saving at epoch 49: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.49297115206718445 train_step: 23500, learning_rate: 4e-05███████████████████████████████▉      | 419/471 [00:06<00:00, 58.10it/s]
epoch 50 iter 470: train loss 0.59135. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 60.21it/s]
test loss: %f 0.364509882791987
epoch_valid_loss: 0.364509882791987, epoch_train_loss: 0.5018697069075964, epoch: 50
Saving at epoch 50: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.48064786195755005 train_step: 24000, learning_rate: 4e-05███████████████████████████████████▎  | 448/471 [00:07<00:00, 69.77it/s]
epoch 51 iter 470: train loss 0.42900. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 63.01it/s]
test loss: %f 0.3654734779079005
epoch_valid_loss: 0.3654734779079005, epoch_train_loss: 0.5025152260330832, epoch: 51
epoch 52 iter 470: train loss 0.52145. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 61.07it/s]
test loss: %f 0.3611027620873361
epoch_valid_loss: 0.3611027620873361, epoch_train_loss: 0.501587666586959, epoch: 52
Saving at epoch 52: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.46248117089271545 train_step: 24500, learning_rate: 4e-05                                        | 8/471 [00:00<00:11, 39.92it/s]
epoch 53 iter 470: train loss 0.56339. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 62.09it/s]
test loss: %f 0.3615214223006986
epoch_valid_loss: 0.3615214223006986, epoch_train_loss: 0.5012720689778621, epoch: 53
step_train_loss: 0.5059746503829956 train_step: 25000, learning_rate: 4e-05                                        | 34/471 [00:00<00:06, 67.05it/s]
epoch 54 iter 470: train loss 0.56760. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 65.08it/s]
test loss: %f 0.3592307758781145
epoch_valid_loss: 0.3592307758781145, epoch_train_loss: 0.5004844805996889, epoch: 54
Saving at epoch 54: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.516313910484314 train_step: 25500, learning_rate: 4e-05                                         | 62/471 [00:01<00:05, 68.76it/s]
epoch 55 iter 470: train loss 0.58967. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 60.33it/s]
test loss: %f 0.35954680504663933
epoch_valid_loss: 0.35954680504663933, epoch_train_loss: 0.500656113439811, epoch: 55
step_train_loss: 0.46289685368537903 train_step: 26000, learning_rate: 4e-05                                       | 94/471 [00:01<00:06, 57.02it/s]
epoch 56 iter 470: train loss 0.54847. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████| 471/471 [00:08<00:00, 57.71it/s]
test loss: %f 0.3625252809164659
epoch_valid_loss: 0.3625252809164659, epoch_train_loss: 0.4971371005801385, epoch: 56
step_train_loss: 0.4763077199459076 train_step: 26500, learning_rate: 4e-05                                       | 120/471 [00:01<00:05, 68.96it/s]
epoch 57 iter 470: train loss 0.43446. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 61.97it/s]
test loss: %f 0.35788567617254435
epoch_valid_loss: 0.35788567617254435, epoch_train_loss: 0.4966618959691114, epoch: 57
Saving at epoch 57: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.4835625886917114 train_step: 27000, learning_rate: 4e-05█▏                                     | 147/471 [00:02<00:05, 63.83it/s]
epoch 58 iter 470: train loss 0.42512. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 66.32it/s]
test loss: %f 0.35892258725076354
epoch_valid_loss: 0.35892258725076354, epoch_train_loss: 0.4982246511681065, epoch: 58
step_train_loss: 0.5712557435035706 train_step: 27500, learning_rate: 4e-05████▋                                  | 177/471 [00:02<00:04, 64.10it/s]
epoch 59 iter 470: train loss 0.48196. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████| 471/471 [00:07<00:00, 65.25it/s]
test loss: %f 0.357569490963558
epoch_valid_loss: 0.357569490963558, epoch_train_loss: 0.49477862185480237, epoch: 59
Saving at epoch 59: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.45472729206085205 train_step: 28000, learning_rate: 4e-05███████▏                              | 207/471 [00:03<00:03, 69.99it/s]
epoch 60 iter 470: train loss 0.37832. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████| 471/471 [00:06<00:00, 68.93it/s]
test loss: %f 0.35599259048138027
epoch_valid_loss: 0.35599259048138027, epoch_train_loss: 0.49487294867286763, epoch: 60
Saving at epoch 60: ./cond_gpt/weights/hw5_test_simplesplit_2layer_2head_16embd_32bs.pt

(.venv) root@MSI:/mnt/c/Daniel 2.0/Junior Year of 25-26/Fall 2025/CSCE 421/hw5# python main.py --task generate --run_name hw5_test
The file './tokenizer/simple_vocab.json' exists. Loading tokenizer.
{'<pad>': 0, '<s>': 1, '</s>': 2, '<unk>': 3, 'I_TURN_RIGHT': 4, 'I_JUMP': 5, 'I_WALK': 6, 'I_TURN_LEFT': 7, 'I_RUN': 8, 'I_LOOK': 9, 'jump': 10, 'opposite': 11, 'right': 12, 'twice': 13, 'and': 14, 'turn': 15, 'thrice': 16, 'run': 17, 'left': 18, 'after': 19, 'walk': 20, 'around': 21, 'look': 22}
loading model
total params: 9408
Accuracy: 0.0299: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 4182/4182 [04:21<00:00, 15.97it/s]
Test accuracy: 0.029890004782400764